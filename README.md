# Federated Learning with Intelligent Reflecting Surface and Multi-Agent Deep Reinforcement Learning for 6G Green IoT Networks

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.8+](https://img.shields.io/badge/TensorFlow-2.8+-orange.svg)](https://tensorflow.org/)
[![PyTorch 1.12+](https://img.shields.io/badge/PyTorch-1.12+-red.svg)](https://pytorch.org/)

This repository contains the implementation of the research paper **"Federated Learning with Intelligent Reflecting Surface and Multi-Agent Deep Reinforcement Learning for 6G Green IoT Networks"** presented at IEEE PIMRC 2024.

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/research-team/fl-irs-madrl-6g.git
cd fl-irs-madrl-6g

# Install dependencies
pip install -r requirements.txt

# Install the package in development mode
pip install -e .

# Run a basic simulation
python examples/basic_simulation.py --devices 20 --rounds 10 --dataset mnist
```

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Examples](#examples)
- [Project Structure](#project-structure)
- [Research Paper](#research-paper)
- [Citation](#citation)
- [Contributing](#contributing)
- [License](#license)

## ğŸ” Overview

This project implements a novel approach to optimize 6G IoT networks by combining:

- **Federated Learning (FL)**: Enables distributed machine learning across IoT devices while preserving privacy
- **Intelligent Reflecting Surface (IRS)**: Enhances wireless communication through programmable electromagnetic surfaces
- **Multi-Agent Deep Reinforcement Learning (MADRL)**: Optimizes resource allocation and energy efficiency

The implementation focuses on **green IoT networks**, emphasizing energy efficiency and sustainable communication in next-generation wireless systems.

### Key Contributions

1. **Integrated FL-IRS Framework**: Novel integration of federated learning with IRS-assisted communication
2. **MADRL-based Optimization**: Multi-agent reinforcement learning for dynamic resource allocation
3. **Energy-Efficient Design**: Green communication strategies for sustainable IoT networks
4. **Comprehensive Evaluation**: Performance analysis across multiple datasets and network conditions

## âœ¨ Features

### Core Functionality
- ğŸŒ **Network Topology Modeling**: 3D positioning system for base stations, IoT devices, and IRS
- ğŸ“¡ **Wireless Channel Simulation**: mmWave channel modeling with path loss and fading
- ğŸ¤– **Federated Learning**: Support for multiple datasets (MNIST, CIFAR-10, custom CSV)
- ğŸ”„ **IRS Optimization**: Phase shift optimization for enhanced communication
- ğŸ¯ **MADRL Agents**: Multi-agent deep Q-network implementation
- ğŸ“Š **Performance Metrics**: Energy efficiency, spectral efficiency, and convergence analysis

### Supported Datasets
- **MNIST**: Handwritten digit recognition
- **CIFAR-10**: Object recognition in natural images
- **Custom CSV**: Support for custom tabular datasets
- **Synthetic Data**: Generated datasets for testing and validation

### Optimization Algorithms
- **FedAvg**: Standard federated averaging
- **IRS Phase Optimization**: Gradient-based and RL-based approaches
- **DQN**: Deep Q-Network for multi-agent coordination
- **Energy-Aware Scheduling**: Green communication protocols

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8 or higher
- CUDA-compatible GPU (optional, for accelerated training)
- 8GB+ RAM recommended

### Step 1: Clone the Repository

```bash
git clone https://github.com/research-team/fl-irs-madrl-6g.git
cd fl-irs-madrl-6g
```

### Step 2: Create Virtual Environment (Recommended)

```bash
# Using conda
conda create -n fl-irs-madrl python=3.9
conda activate fl-irs-madrl

# Using venv
python -m venv fl-irs-madrl
source fl-irs-madrl/bin/activate  # On Windows: fl-irs-madrl\Scripts\activate
```

### Step 3: Install Dependencies

```bash
# Install core dependencies
pip install -r requirements.txt

# Install the package in development mode
pip install -e .

# For development (optional)
pip install -e ".[dev]"
```

### Step 4: Verify Installation

```bash
# Run tests to verify installation
python -m pytest tests/ -v

# Run a quick simulation
python examples/basic_simulation.py --devices 5 --rounds 3
```

## ğŸ“– Usage

### Basic Simulation

Run a complete FL-IRS simulation with default parameters:

```python
from src.core.network_topology import NetworkTopology
from src.core.federated_learning import FederatedLearning
from src.core.irs_optimization import IRSOptimizer

# Initialize network
network = NetworkTopology(num_iot_devices=20, num_irs_elements=100)

# Setup federated learning
fl_system = FederatedLearning(
    num_devices=20,
    dataset='mnist',
    local_epochs=5,
    batch_size=32
)

# Optimize IRS configuration
irs_optimizer = IRSOptimizer(network.irs, network.channel_model)
optimal_phases = irs_optimizer.optimize()

# Run federated learning
results = fl_system.train(num_rounds=10)
```

### Command Line Interface

The repository includes several command-line scripts for different scenarios:

```bash
# Basic simulation with custom parameters
python examples/basic_simulation.py \
    --devices 30 \
    --rounds 20 \
    --dataset cifar10 \
    --distribution non_iid \
    --channel poor

# Performance analysis
python examples/performance_analysis.py \
    --compare_methods \
    --save_results results/comparison.json

# Kaggle dataset integration
python examples/kaggle_integration.py \
    --dataset titanic \
    --preprocessing standard

# MADRL demonstration
python examples/madrl_demo.py \
    --agents 5 \
    --episodes 1000 \
    --environment green_iot
```

### Configuration

Customize simulation parameters through configuration files:

```python
# src/config/settings.py
NETWORK_CONFIG = {
    'num_iot_devices': 20,
    'num_irs_elements': 100,
    'area_size': 100.0,
    'bs_position': (50.0, 50.0, 10.0),
    'irs_position': (100.0, 50.0, 5.0)
}

FL_CONFIG = {
    'local_epochs': 5,
    'batch_size': 32,
    'learning_rate': 0.001,
    'num_rounds': 100
}
```

## ğŸ¯ Examples

### Example 1: Network Topology Visualization

```python
import matplotlib.pyplot as plt
from src.core.network_topology import NetworkTopology
from src.utils.visualization import plot_network_topology

# Create network
network = NetworkTopology(num_iot_devices=15)

# Visualize topology
fig, ax = plt.subplots(figsize=(10, 8))
plot_network_topology(network, ax)
plt.title("6G IoT Network with IRS")
plt.show()
```

### Example 2: Federated Learning with Different Datasets

```python
from src.core.federated_learning import FederatedLearning

# MNIST dataset
fl_mnist = FederatedLearning(dataset='mnist', num_devices=10)
results_mnist = fl_mnist.train(num_rounds=20)

# CIFAR-10 dataset
fl_cifar = FederatedLearning(dataset='cifar10', num_devices=10)
results_cifar = fl_cifar.train(num_rounds=20)

# Custom CSV dataset
fl_custom = FederatedLearning(
    dataset='custom',
    data_path='data/my_dataset.csv',
    target_column='label'
)
results_custom = fl_custom.train(num_rounds=15)
```

### Example 3: IRS Optimization

```python
from src.core.irs_optimization import IRSOptimizer
from src.core.network_topology import NetworkTopology

# Setup network
network = NetworkTopology()

# Initialize IRS optimizer
optimizer = IRSOptimizer(
    irs=network.irs,
    channel_model=network.channel_model,
    optimization_method='gradient'
)

# Optimize phase shifts
optimal_phases = optimizer.optimize()
performance_gain = optimizer.evaluate_performance(optimal_phases)

print(f"Performance improvement: {performance_gain:.2f} dB")
```

### Example 4: Multi-Agent Reinforcement Learning

```python
from src.core.madrl_agent import MADRLAgent, MultiAgentEnvironment

# Create multi-agent environment
env = MultiAgentEnvironment(
    num_agents=5,
    network_topology=network,
    reward_type='energy_efficiency'
)

# Initialize agents
agents = [MADRLAgent(agent_id=i) for i in range(5)]

# Training loop
for episode in range(1000):
    states = env.reset()
    done = False
    
    while not done:
        actions = [agent.act(state) for agent, state in zip(agents, states)]
        next_states, rewards, done, info = env.step(actions)
        
        # Update agents
        for agent, state, action, reward, next_state in zip(
            agents, states, actions, rewards, next_states
        ):
            agent.learn(state, action, reward, next_state, done)
        
        states = next_states
```

## ğŸ“ Project Structure

```
fl-irs-madrl-6g/
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ LICENSE                       # MIT License
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ setup.py                      # Package installation
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ methodology.md            # Research methodology
â”‚   â”œâ”€â”€ api/                      # API documentation
â”‚   â”œâ”€â”€ paper/                    # Research paper
â”‚   â””â”€â”€ tutorials/                # Usage tutorials
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                     # Core implementations
â”‚   â”‚   â”œâ”€â”€ network_topology.py   # Network modeling
â”‚   â”‚   â”œâ”€â”€ channel_model.py      # Wireless channels
â”‚   â”‚   â”œâ”€â”€ federated_learning.py # FL implementation
â”‚   â”‚   â”œâ”€â”€ irs_optimization.py   # IRS optimization
â”‚   â”‚   â””â”€â”€ madrl_agent.py        # MADRL agents
â”‚   â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”‚   â”œâ”€â”€ data_processing.py    # Data handling
â”‚   â”‚   â”œâ”€â”€ visualization.py      # Plotting functions
â”‚   â”‚   â””â”€â”€ metrics.py            # Performance metrics
â”‚   â””â”€â”€ config/                   # Configuration
â”‚       â””â”€â”€ settings.py           # Default settings
â”‚
â”œâ”€â”€ examples/                     # Example scripts
â”‚   â”œâ”€â”€ basic_simulation.py       # Basic FL-IRS demo
â”‚   â”œâ”€â”€ kaggle_integration.py     # Dataset integration
â”‚   â”œâ”€â”€ performance_analysis.py   # Performance evaluation
â”‚   â”œâ”€â”€ madrl_demo.py             # MADRL demonstration
â”‚   â””â”€â”€ notebooks/                # Jupyter tutorials
â”‚       â””â”€â”€ tutorial.ipynb        # Step-by-step guide
â”‚
â”œâ”€â”€ tests/                        # Unit tests
â”‚   â”œâ”€â”€ test_network_topology.py
â”‚   â”œâ”€â”€ test_federated_learning.py
â”‚   â”œâ”€â”€ test_irs_optimization.py
â”‚   â””â”€â”€ test_madrl_agent.py
â”‚
â”œâ”€â”€ data/                         # Data directory
â”‚   â”œâ”€â”€ synthetic/                # Generated datasets
â”‚   â””â”€â”€ real/                     # Real dataset samples
â”‚
â””â”€â”€ results/                      # Experimental results
    â”œâ”€â”€ figures/                  # Generated plots
    â””â”€â”€ logs/                     # Simulation logs
```


### Abstract

The paper proposes a novel framework that integrates federated learning with intelligent reflecting surfaces and multi-agent deep reinforcement learning to optimize 6G IoT networks. The approach addresses key challenges in next-generation wireless systems including energy efficiency, privacy preservation, and dynamic resource allocation.

### Key Technical Contributions

1. **FL-IRS Integration**: Novel framework combining federated learning with IRS-assisted communication
2. **MADRL Optimization**: Multi-agent reinforcement learning for resource allocation
3. **Green Communication**: Energy-efficient protocols for sustainable IoT networks
4. **Performance Analysis**: Comprehensive evaluation across multiple scenarios

### Experimental Results

The implementation demonstrates significant improvements in:
- **Energy Efficiency**: Up to 35% reduction in power consumption
- **Communication Quality**: 20% improvement in signal-to-noise ratio
- **Learning Convergence**: 25% faster convergence compared to baseline methods
- **Network Scalability**: Support for 100+ IoT devices

## ğŸ“š Citation

If you use this code in your research, please cite our paper:


## ğŸ¤ Contributing

We welcome contributions from the research community! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Clone and setup development environment
git clone https://github.com/research-team/fl-irs-madrl-6g.git
cd fl-irs-madrl-6g

# Install development dependencies
pip install -e ".[dev]"

# Run tests
python -m pytest tests/ -v

# Run code formatting
black src/ tests/ examples/
flake8 src/ tests/ examples/
```

### Reporting Issues

Please use the [GitHub Issues](https://github.com/research-team/fl-irs-madrl-6g/issues) page to report bugs or request features.

## ğŸ“ Support

For questions about the implementation or research:

- **Issues**: [GitHub Issues](https://github.com/research-team/fl-irs-madrl-6g/issues)
- **Discussions**: [GitHub Discussions](https://github.com/research-team/fl-irs-madrl-6g/discussions)

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- The open-source community for providing excellent tools and libraries

---

**Keywords**: Federated Learning, Intelligent Reflecting Surface, Multi-Agent Deep Reinforcement Learning, 6G Networks, Green IoT, Energy Efficiency, Wireless Communication